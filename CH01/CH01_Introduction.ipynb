{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HexS4eAsRQ1"
   },
   "source": [
    "# TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "QLrk1ZnKsRQ8",
    "outputId": "573b6379-aeea-4156-a09c-2230ef05424a"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "toy_corpus = [\"the fat cat sat on the mat\", \"the big cat slept\", \"the dog chased a cat\"]\n",
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "\n",
    "corpus_tfidf = vectorizer.fit_transform(toy_corpus)\n",
    "\n",
    "print(f\"The vocabulary size is {len(vectorizer.vocabulary_.keys())} \")\n",
    "print(f\"The document-term matrix shape is {corpus_tfidf.shape}\")\n",
    "\n",
    "df = pd.DataFrame(np.round(corpus_tfidf.toarray(), 2))\n",
    "df.columns = vectorizer.get_feature_names()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQI1-eQDXuvZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7S1Wf2xWqH-"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQ_wnwpCsRQ9",
    "outputId": "3988dbf1-9b29-4fd4-bf2a-7dcbb0e9f075"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "labels = [0, 1, 0]\n",
    "clf = SVC()\n",
    "clf.fit(df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P1UfliHPXotq",
    "outputId": "11971404-077e-4681-be5d-e8a3aa95eebe"
   },
   "outputs": [],
   "source": [
    "clf.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7Xp7alkCb0L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIpBd5b_sRQ_"
   },
   "source": [
    "# Building a LM Model \n",
    "Once we prepared our corpus above, we are ready to start training Maximum Likelihood Estimator (MLE) as a Language Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUGnkes_sRRA"
   },
   "source": [
    "## Training a bigram LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gLP2eGrBmJTz",
    "outputId": "55c36aca-dfd1-4f05-9584-53900abb6310"
   },
   "outputs": [],
   "source": [
    "!pip install nltk==3.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DXhFj8Bk9hNI",
    "outputId": "cb579144-cbf8-4335-de75-f58cdce4e19a"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "nltk.download(\"gutenberg\")\n",
    "nltk.download(\"punkt\")\n",
    "macbeth = gutenberg.sents(\"shakespeare-macbeth.txt\")\n",
    "\n",
    "model, vocab = padded_everygram_pipeline(2, macbeth)\n",
    "lm = MLE(2)\n",
    "lm.fit(model, vocab)\n",
    "print(list(lm.vocab)[:40])\n",
    "print(f\"The number of words is {len(lm.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7r_k7HsEIl5",
    "outputId": "77a4b812-aadb-467a-c839-fbe8bf3639e4"
   },
   "outputs": [],
   "source": [
    "print(macbeth[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAmNlJAusRRC"
   },
   "source": [
    "## See what LM learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-9V4zpqsRRC"
   },
   "source": [
    "Here is a list of what the language model learded so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Imi-8nJBsRRC",
    "outputId": "998fe046-ae85-499d-eb88-62a616d8373f"
   },
   "outputs": [],
   "source": [
    "print(f\"The frequency of the term 'Macbeth' is {lm.counts['Macbeth']}\")\n",
    "print(f\"The language model probability score of 'Macbeth' is {lm.score('Macbeth')}\")\n",
    "print(\n",
    "    f\"The number of times 'Macbeth' follows 'Enter' is {lm.counts[['Enter']]['Macbeth']} \"\n",
    ")\n",
    "print(f\"P(Macbeth | Enter) is {lm.score('Macbeth', ['Enter'])}\")\n",
    "print(f\"P(shaking | for) is {lm.score('shaking', ['for'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oauTwshSsRRD"
   },
   "source": [
    "## Language Generation with LM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVxMOl7csRRD"
   },
   "source": [
    "To generate one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "zhpjmp1_sRRD",
    "outputId": "c2f8ce54-2df2-4e66-b85f-411b2c3f1424"
   },
   "outputs": [],
   "source": [
    "lm.generate(1, random_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8NjYNyXsRRE"
   },
   "source": [
    "To generate a sentence of 7 words length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jq7dnLXQsRRE",
    "outputId": "1cfc5080-03ea-4ccb-aaec-f251c550d509"
   },
   "outputs": [],
   "source": [
    "print(lm.generate(7, random_seed=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NK3EDt-_sRRE"
   },
   "source": [
    "To generate 10 words starting with \\<s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inFO4hKqsRRF",
    "outputId": "1e1f8861-ff67-4787-dfb8-9522b48ff04b"
   },
   "outputs": [],
   "source": [
    "lm.generate(10, text_seed=[\"<s>\"], random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUqLMMuPJjOj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsT0yIeFJuu3"
   },
   "source": [
    "# Word Embeddings Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSXGUZAdKhFt",
    "outputId": "7733b901-7e9e-4d39-ded4-619c874bc81e"
   },
   "outputs": [],
   "source": [
    "!pip install gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwIt376DJxEK"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(\n",
    "    sentences=macbeth, size=100, window=4, min_count=10, workers=4, iter=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x1N8FgE0KKyu",
    "outputId": "aab62da2-9e3f-46aa-b84a-be0fedd5d26b"
   },
   "outputs": [],
   "source": [
    "model.wv.similar_by_word(\"then\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zfg_9ct1LVxK",
    "outputId": "941c99d1-f3f1-4104-f77e-70850f109233"
   },
   "outputs": [],
   "source": [
    "model.wv[\"did\"]  # get numpy vector of word 'Macbeth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "OPmlCHpEOviN",
    "outputId": "096f03cd-882d-4366-81b9-1b05546802d8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "words = list([e for e in model.wv.vocab if len(e) > 4])  # plot words longer than 4\n",
    "random.shuffle(words)\n",
    "words3d = PCA(n_components=3, random_state=42).fit_transform(model.wv[words[:100]])\n",
    "\n",
    "\n",
    "def plotWords3D(vecs, words, title):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    vecs : numpy-array\n",
    "        Transformed 3D array either by PCA or other techniques\n",
    "    words: a list of word\n",
    "        the word list to be mapped\n",
    "    title: str\n",
    "        The title of plot\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "    ax = fig.gca(projection=\"3d\")\n",
    "    for w, vec in zip(words, vecs):\n",
    "        ax.text(\n",
    "            vec[0],\n",
    "            vec[1],\n",
    "            vec[2],\n",
    "            w,\n",
    "            color=np.random.rand(\n",
    "                3,\n",
    "            ),\n",
    "        )\n",
    "    ax.set_xlim(min(vecs[:, 0]), max(vecs[:, 0]))\n",
    "    ax.set_ylim(min(vecs[:, 1]), max(vecs[:, 1]))\n",
    "    ax.set_zlim(min(vecs[:, 2]), max(vecs[:, 2]))\n",
    "    ax.set_xlabel(\"DIM-1\")\n",
    "    ax.set_ylabel(\"DIM-2\")\n",
    "    ax.set_zlabel(\"DIM-3\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotWords3D(words3d, words, \"Visualizing Word2Vec Word Embeddings using PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9VDm2Vtc4xFo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "837iPJSNbo26"
   },
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kIsedoNucJCG",
    "outputId": "a6563d51-814a-4b0e-bbe2-ac6100b1851c"
   },
   "outputs": [],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ulrs6E1upH5t"
   },
   "outputs": [],
   "source": [
    "# Parameters min_n and max_n take control the lengths of character ngrams.\n",
    "# If max_n is set to 0, no character ngrams are used, and the model turns out to be Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F1wr4O1VACGQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "hcZLmhA9X27E",
    "outputId": "b7e610ef-f0c0-497d-8c1b-f4ba71959dd9"
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "model = FastText(\n",
    "    sentences=macbeth,\n",
    "    size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    workers=4,\n",
    "    iter=10,\n",
    "    word_ngrams=3,\n",
    ")\n",
    "# min_n: min length of char ngrams (Default 3)\n",
    "# max_n: max length of char ngrams (Default 6)\n",
    "\n",
    "np.random.seed(42)\n",
    "words = [w[0] for w in model.wv.similar_by_word(\"Macbeth\", 50)]\n",
    "words3d = PCA(n_components=3, random_state=42).fit_transform(model.wv[words])\n",
    "plotWords3D(words3d, words, \"Visualizing FastText Word Embeddings reduced by PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IY3jIMXfEHoA"
   },
   "outputs": [],
   "source": [
    "## Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r_4IBcFRclR4",
    "outputId": "b967e317-c5d4-468c-f6f4-b20e8786f66c"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "info = api.info()  # show info about available models/datasets\n",
    "model = api.load(\n",
    "    \"glove-twitter-25\"\n",
    ")  # download the model and return as object ready for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TC1Fidlj252p",
    "outputId": "a23e551f-e819-4857-c0f0-96fc5dcb8d24"
   },
   "outputs": [],
   "source": [
    "model.most_similar(\"java\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpI5zJ9YATZO"
   },
   "source": [
    "# LSTM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IoTKPtG_tps"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mDsco68MPkJA",
    "outputId": "501b0cd1-fe1d-407b-f475-ee6f65daad13"
   },
   "outputs": [],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/glue/data/SST-2.zip\n",
    "!unzip SST-2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Yllu1PjSyC0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"SST-2/train.tsv\", sep=\"\\t\")\n",
    "sentences = df.sentence\n",
    "labels = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "id": "jus1GqxwEMhB",
    "outputId": "23ece364-5b0f-43bc-de8c-7c65e314840b"
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6iPoTC4JVloe"
   },
   "outputs": [],
   "source": [
    "max_sen_len = max([len(s.split()) for s in sentences])\n",
    "words = [\"PAD\"] + list(set([w for s in sentences for w in s.split()]))\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "max_words = max(word2idx.values()) + 1\n",
    "idx2word = {i: w for i, w in enumerate(words)}\n",
    "# preparing training set\n",
    "train = [list(map(lambda x: word2idx[x], s.split())) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yBsK55mj19CG",
    "outputId": "22a73be7-d0fd-4c2f-a224-ce57af9d6485"
   },
   "outputs": [],
   "source": [
    "len(train), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pjCygCh13UzG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HM6zsPObxmX3",
    "outputId": "d8268f2c-5e0d-4ad4-d619-6fdaf6c4fac2"
   },
   "outputs": [],
   "source": [
    "sum(labels), len(labels), sum(labels) / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7lAL50bBS0va",
    "outputId": "d2180d45-34b2-4c9e-b869-71d8be890dac"
   },
   "outputs": [],
   "source": [
    "from keras import preprocessing\n",
    "\n",
    "train_pad = preprocessing.sequence.pad_sequences(train, maxlen=max_sen_len)\n",
    "print(\"train shape:\", train_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UnIv64YPvQcG",
    "outputId": "954641f9-1b87-4687-922a-bb6fba1ad18e"
   },
   "outputs": [],
   "source": [
    "print(train_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gKhKSe08Tcf2",
    "outputId": "787fed4f-b99c-43e3-b01d-653c9833595d"
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Embedding, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "history = model.fit(train_pad, labels, epochs=15, batch_size=16, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vszr-ZGQyHb2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "id": "-kweoS1TQxlz",
    "outputId": "e886dd67-48b7-43bb-a2e2-d78149e86969"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history[\"val_\" + string])\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, \"val_\" + string])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_graphs(history, \"acc\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EdrPQ2_YNrDP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7mTzm29TPHxp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H62wP0TBPkYq",
    "outputId": "3a435cfe-e2eb-4df4-df31-4e2618a32c1a"
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_words, 32, input_length=max_sen_len))\n",
    "model.add(layers.Conv1D(32, 8, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling1D(4))\n",
    "model.add(layers.Conv1D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "model.compile(loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "history = model.fit(train_pad, labels, epochs=15, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "4efxKSyAgeqr",
    "outputId": "d2c5ee1c-ec5b-4ea1-fb70-a3cb4d5d999a"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history, \"acc\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E_ovau06hzM7",
    "outputId": "e71ae11f-50c9-432b-ea02-5e97d78f777a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5he0sjA9XTOM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CH01 Introduction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
