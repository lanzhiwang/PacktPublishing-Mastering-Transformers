{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtyN9XsZ245Q"
      },
      "source": [
        "# 2. A Hands-On Introduction to the Subject\n",
        "\n",
        "##### Working with Language Models and Tokenizers\n",
        "\n",
        "## Preparation for Google Collab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "print(os.listdir(\"/content/drive/MyDrive/\"))\n",
        "\n",
        "print(os.listdir(\"/content/drive/MyDrive/Colab Notebooks\"))\n",
        "\n",
        "if os.getcwd() != \"/content/drive/MyDrive\":\n",
        "    os.chdir(\"/content/drive/MyDrive\")\n",
        "\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq0p5Wl2Cmsk",
        "outputId": "f8cc91b3-3052-4c52-ec48-5c66ee8782e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive\n",
            "['Colab Notebooks', 'requirements.txt']\n",
            "['CH02a_Working_with_Language_Models_and_Tokenizers.ipynb']\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apmWcx6z23Z1"
      },
      "outputs": [],
      "source": [
        "!pip install -r /content/drive/MyDrive/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ch02"
      ],
      "metadata": {
        "id": "3H5HI_-eCmv8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install tree && tree -a \"/content/drive/MyDrive/ch02\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkWstnAnCmzJ",
        "outputId": "df8606ba-6305-4f5a-d927-61530946a42f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 47.9 kB of archives.\n",
            "After this operation, 116 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tree amd64 2.0.2-1 [47.9 kB]\n",
            "Fetched 47.9 kB in 1s (45.5 kB/s)\n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 124947 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_2.0.2-1_amd64.deb ...\n",
            "Unpacking tree (2.0.2-1) ...\n",
            "Setting up tree (2.0.2-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[01;34m/content/drive/MyDrive/ch02\u001b[0m\n",
            "\n",
            "0 directories, 0 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MQ_9wGWnXBd"
      },
      "outputs": [],
      "source": [
        "# 分词器\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsUDrgT3laqs"
      },
      "outputs": [],
      "source": [
        "# !apt-get install tree\n",
        "!tree -a ~/.cache/huggingface/hub/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsXEwG1k-Dkl"
      },
      "source": [
        "### 和分词器相关的文件\n",
        "\n",
        "1. tokenizer_config.json\n",
        "2. vocab.txt\n",
        "3. tokenizer.json\n",
        "4. config.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsDSpHlX-qd-"
      },
      "outputs": [],
      "source": [
        "! cat ~/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgCjMg0F-5R9"
      },
      "outputs": [],
      "source": [
        "! cat ~/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer_config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrcsgviR-5VG"
      },
      "outputs": [],
      "source": [
        "! cat ~/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cecWGI_e-5YW"
      },
      "outputs": [],
      "source": [
        "! cat ~/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/vocab.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YGDDnaMncAW"
      },
      "outputs": [],
      "source": [
        "text = \"Using transformers is easy!\"\n",
        "tokenizer(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I7AUzIa-Dkm"
      },
      "source": [
        "### 输出字段的含义, 不同的分词器输出不一样\n",
        "\n",
        "1. input_ids\n",
        "2. token_type_ids\n",
        "3. attention_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wiigdlCnfQJ"
      },
      "outputs": [],
      "source": [
        "encoded_input = tokenizer(text, return_tensors=\"pt\")\n",
        "encoded_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qm1YaZBMni6d"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "print(\"model:\", model)\n",
        "\n",
        "output = model(**encoded_input)\n",
        "print(\"output:\", output.last_hidden_state.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9k18qFQ_xhH"
      },
      "outputs": [],
      "source": [
        "!tree -a ~/.cache/huggingface/hub/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IVD8dAf-Dkn"
      },
      "source": [
        "model.safetensors 文件作用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWwtnWLs_86L"
      },
      "outputs": [],
      "source": [
        "! file ~/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/model.safetensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUSqcni1nsgL"
      },
      "outputs": [],
      "source": [
        "# 包含 TF 前缀\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "print(\"tokenizer:\", tokenizer)\n",
        "\n",
        "model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
        "print(\"model:\", model)\n",
        "\n",
        "text = \" Using transformers is easy!\"\n",
        "\n",
        "encoded_input = tokenizer(text, return_tensors=\"tf\")\n",
        "print(\"encoded_input:\", encoded_input)\n",
        "\n",
        "output = model(**encoded_input)\n",
        "print(\"output:\", output.last_hidden_state.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIqIZ6-Jn3n8"
      },
      "outputs": [],
      "source": [
        "# pipeline\n",
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
        "print(\"unmasker:\", unmasker)\n",
        "\n",
        "unmasker(\"The man worked as a [MASK].\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNR6jL6uoDB5"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "print(\"classifier:\", classifier)\n",
        "\n",
        "sequence_to_classify = \"I am going to france.\"\n",
        "candidate_labels = [\"travel\", \"cooking\", \"dancing\"]\n",
        "\n",
        "classifier(sequence_to_classify, candidate_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKxJkxmh-Dko"
      },
      "outputs": [],
      "source": [
        "!tree -a ~/.cache/huggingface/hub/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xsUJLQvBnAt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}