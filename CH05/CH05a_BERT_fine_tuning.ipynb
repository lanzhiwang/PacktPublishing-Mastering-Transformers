{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr50xchZunFD"
      },
      "source": [
        "# Fine-tuning BERT model for Binary Text Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tszbPHwjFfkP"
      },
      "source": [
        "## Preparation for Google Collab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wW9BBcot81Q",
        "outputId": "094ffea2-c8ed-45ce-b497-9d6ac3de9a36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nnk--05txiWB",
        "outputId": "6f86272e-95c4-44f8-9b14-5c004ff07212"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IbXLHjWfxiZJ",
        "outputId": "41fbb786-22fa-4973-b008-7dbedd468826"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/MyBert'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdsTbNMexici",
        "outputId": "628f7a4d-7e56-412f-c693-96e7ac4304ad"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CH05a_BERT_fine-tuning.ipynb', 'MyBert']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.getcwd() != \"/content/drive/MyDrive/Colab Notebooks/MyBert\":\n",
        "    os.chdir(\"/content/drive/MyDrive/Colab Notebooks/MyBert\")"
      ],
      "metadata": {
        "id": "PRMfNmF9xif6"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vKIPYkcxxiix",
        "outputId": "ae62a81d-4c7e-4809-f316-dbc89442321b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/MyBert'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content/drive/MyDrive/Colab Notebooks/MyBert\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfYIMeAnximL",
        "outputId": "5a080fa3-b850-4f3d-8d21-27c6f9a28099"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install tree && tree -a \"/content/drive/MyDrive/Colab Notebooks/MyBert\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-Ze0DKdxipV",
        "outputId": "164fb27c-f7f8-4272-e47e-549d82ce044f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tree is already the newest version (2.0.2-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n",
            "\u001b[01;34m/content/drive/MyDrive/Colab Notebooks/MyBert\u001b[0m\n",
            "\n",
            "0 directories, 0 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZv1tmcx_pNo"
      },
      "source": [
        "## Loading pre-trained model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE1Rwh2BtnwT",
        "outputId": "4e5762dd-f046-4024-ffbc-e528e1f941a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
              "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
        "\n",
        "model_path = \"distilbert-base-uncased\"\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(model_path)\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    model_path, id2label={0: \"NEG\", 1: \"POS\"}, label2id={\"NEG\": 0, \"POS\": 1}\n",
        ")\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Inr7spweyqC1",
        "outputId": "12b0fec7-8ab0-4c91-9dab-6c89d9bd3a5b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "licNE7yQS8uw"
      },
      "source": [
        "## Loading popular IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "w2HdjLQEXTos"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# to take entire dataset from original train 25 K AND TEST 25K\n",
        "\"\"\"\n",
        "imdb_train= load_dataset('imdb', split=\"train\")\n",
        "imdb_test= load_dataset('imdb', split=\"test[:6250]+test[-6250:]\")\n",
        "imdb_val= load_dataset('imdb', split=\"test[6250:12500]+test[-12500:-6250]\")\n",
        "\n",
        "\"\"\"\n",
        "# to take smaller portion 4K for train, 1K for test and 1K for validation\n",
        "imdb_train = load_dataset(\"imdb\", split=\"train[:2000]+train[-2000:]\")\n",
        "imdb_test = load_dataset(\"imdb\", split=\"test[:500]+test[-500:]\")\n",
        "imdb_val = load_dataset(\"imdb\", split=\"test[500:1000]+test[-1000:-500]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kfFp7nkbki4",
        "outputId": "b50a76fb-0302-402e-bdcf-66bd2fd17c35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4000, 2), (1000, 2), (1000, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "imdb_train.shape, imdb_test.shape, imdb_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEFT9oy1zHbx",
        "outputId": "16735687-ac3f-43bd-e408-d53a713d8ff2"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
              " 'label': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8ca51ba617f840c185453cb68d98f5de",
            "6a6bed2f9a7e41b0bc107df622b785a0",
            "7d5d85b9c4754cbeac195d6b34771fa5",
            "05853654c2fa4eb38560041b617c3335",
            "bec7decff2ef49daace63d161a5baeb3",
            "e6d42e26f7cc4ab0bfd31ec1d0539c35",
            "82fbc94f764f4038816e619ea4a19ef4",
            "952c865c7c844a9090b83fcb9207f10c",
            "64eacb2d9c1342198c69f4ad6d257df9",
            "98cb9bf77139496c9eec835f98f13a1c",
            "dd5a789f66d6469b95ac69c599afcd6f"
          ]
        },
        "id": "WpuCsmUVXgm9",
        "outputId": "cc0a59e3-ab64-4a8b-d18e-884d9c44a03f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ca51ba617f840c185453cb68d98f5de"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "enc_train = imdb_train.map(\n",
        "    lambda e: tokenizer(e[\"text\"], padding=True, truncation=True),\n",
        "    batched=True,\n",
        "    batch_size=1000,\n",
        ")\n",
        "enc_test = imdb_test.map(\n",
        "    lambda e: tokenizer(e[\"text\"], padding=True, truncation=True),\n",
        "    batched=True,\n",
        "    batch_size=1000,\n",
        ")\n",
        "enc_val = imdb_val.map(\n",
        "    lambda e: tokenizer(e[\"text\"], padding=True, truncation=True),\n",
        "    batched=True,\n",
        "    batch_size=1000,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_train.shape, enc_test.shape, enc_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTc0O9GCzSTu",
        "outputId": "3855c9d6-3cae-48c4-ea53-e0f42e036ac6"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4000, 4), (1000, 4), (1000, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voRNdu4tziYN",
        "outputId": "381f06fd-9461-4e03-c317-a60de360ce1b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
              " 'label': 0,\n",
              " 'input_ids': [101,\n",
              "  1045,\n",
              "  12524,\n",
              "  1045,\n",
              "  2572,\n",
              "  8025,\n",
              "  1011,\n",
              "  3756,\n",
              "  2013,\n",
              "  2026,\n",
              "  2678,\n",
              "  3573,\n",
              "  2138,\n",
              "  1997,\n",
              "  2035,\n",
              "  1996,\n",
              "  6704,\n",
              "  2008,\n",
              "  5129,\n",
              "  2009,\n",
              "  2043,\n",
              "  2009,\n",
              "  2001,\n",
              "  2034,\n",
              "  2207,\n",
              "  1999,\n",
              "  3476,\n",
              "  1012,\n",
              "  1045,\n",
              "  2036,\n",
              "  2657,\n",
              "  2008,\n",
              "  2012,\n",
              "  2034,\n",
              "  2009,\n",
              "  2001,\n",
              "  8243,\n",
              "  2011,\n",
              "  1057,\n",
              "  1012,\n",
              "  1055,\n",
              "  1012,\n",
              "  8205,\n",
              "  2065,\n",
              "  2009,\n",
              "  2412,\n",
              "  2699,\n",
              "  2000,\n",
              "  4607,\n",
              "  2023,\n",
              "  2406,\n",
              "  1010,\n",
              "  3568,\n",
              "  2108,\n",
              "  1037,\n",
              "  5470,\n",
              "  1997,\n",
              "  3152,\n",
              "  2641,\n",
              "  1000,\n",
              "  6801,\n",
              "  1000,\n",
              "  1045,\n",
              "  2428,\n",
              "  2018,\n",
              "  2000,\n",
              "  2156,\n",
              "  2023,\n",
              "  2005,\n",
              "  2870,\n",
              "  1012,\n",
              "  1026,\n",
              "  7987,\n",
              "  1013,\n",
              "  1028,\n",
              "  1026,\n",
              "  7987,\n",
              "  1013,\n",
              "  1028,\n",
              "  1996,\n",
              "  5436,\n",
              "  2003,\n",
              "  8857,\n",
              "  2105,\n",
              "  1037,\n",
              "  2402,\n",
              "  4467,\n",
              "  3689,\n",
              "  3076,\n",
              "  2315,\n",
              "  14229,\n",
              "  2040,\n",
              "  4122,\n",
              "  2000,\n",
              "  4553,\n",
              "  2673,\n",
              "  2016,\n",
              "  2064,\n",
              "  2055,\n",
              "  2166,\n",
              "  1012,\n",
              "  1999,\n",
              "  3327,\n",
              "  2016,\n",
              "  4122,\n",
              "  2000,\n",
              "  3579,\n",
              "  2014,\n",
              "  3086,\n",
              "  2015,\n",
              "  2000,\n",
              "  2437,\n",
              "  2070,\n",
              "  4066,\n",
              "  1997,\n",
              "  4516,\n",
              "  2006,\n",
              "  2054,\n",
              "  1996,\n",
              "  2779,\n",
              "  25430,\n",
              "  14728,\n",
              "  2245,\n",
              "  2055,\n",
              "  3056,\n",
              "  2576,\n",
              "  3314,\n",
              "  2107,\n",
              "  2004,\n",
              "  1996,\n",
              "  5148,\n",
              "  2162,\n",
              "  1998,\n",
              "  2679,\n",
              "  3314,\n",
              "  1999,\n",
              "  1996,\n",
              "  2142,\n",
              "  2163,\n",
              "  1012,\n",
              "  1999,\n",
              "  2090,\n",
              "  4851,\n",
              "  8801,\n",
              "  1998,\n",
              "  6623,\n",
              "  7939,\n",
              "  4697,\n",
              "  3619,\n",
              "  1997,\n",
              "  8947,\n",
              "  2055,\n",
              "  2037,\n",
              "  10740,\n",
              "  2006,\n",
              "  4331,\n",
              "  1010,\n",
              "  2016,\n",
              "  2038,\n",
              "  3348,\n",
              "  2007,\n",
              "  2014,\n",
              "  3689,\n",
              "  3836,\n",
              "  1010,\n",
              "  19846,\n",
              "  1010,\n",
              "  1998,\n",
              "  2496,\n",
              "  2273,\n",
              "  1012,\n",
              "  1026,\n",
              "  7987,\n",
              "  1013,\n",
              "  1028,\n",
              "  1026,\n",
              "  7987,\n",
              "  1013,\n",
              "  1028,\n",
              "  2054,\n",
              "  8563,\n",
              "  2033,\n",
              "  2055,\n",
              "  1045,\n",
              "  2572,\n",
              "  8025,\n",
              "  1011,\n",
              "  3756,\n",
              "  2003,\n",
              "  2008,\n",
              "  2871,\n",
              "  2086,\n",
              "  3283,\n",
              "  1010,\n",
              "  2023,\n",
              "  2001,\n",
              "  2641,\n",
              "  26932,\n",
              "  1012,\n",
              "  2428,\n",
              "  1010,\n",
              "  1996,\n",
              "  3348,\n",
              "  1998,\n",
              "  16371,\n",
              "  25469,\n",
              "  5019,\n",
              "  2024,\n",
              "  2261,\n",
              "  1998,\n",
              "  2521,\n",
              "  2090,\n",
              "  1010,\n",
              "  2130,\n",
              "  2059,\n",
              "  2009,\n",
              "  1005,\n",
              "  1055,\n",
              "  2025,\n",
              "  2915,\n",
              "  2066,\n",
              "  2070,\n",
              "  10036,\n",
              "  2135,\n",
              "  2081,\n",
              "  22555,\n",
              "  2080,\n",
              "  1012,\n",
              "  2096,\n",
              "  2026,\n",
              "  2406,\n",
              "  3549,\n",
              "  2568,\n",
              "  2424,\n",
              "  2009,\n",
              "  16880,\n",
              "  1010,\n",
              "  1999,\n",
              "  4507,\n",
              "  3348,\n",
              "  1998,\n",
              "  16371,\n",
              "  25469,\n",
              "  2024,\n",
              "  1037,\n",
              "  2350,\n",
              "  18785,\n",
              "  1999,\n",
              "  4467,\n",
              "  5988,\n",
              "  1012,\n",
              "  2130,\n",
              "  13749,\n",
              "  7849,\n",
              "  24544,\n",
              "  1010,\n",
              "  15835,\n",
              "  2037,\n",
              "  3437,\n",
              "  2000,\n",
              "  2204,\n",
              "  2214,\n",
              "  2879,\n",
              "  2198,\n",
              "  4811,\n",
              "  1010,\n",
              "  2018,\n",
              "  3348,\n",
              "  5019,\n",
              "  1999,\n",
              "  2010,\n",
              "  3152,\n",
              "  1012,\n",
              "  1026,\n",
              "  7987,\n",
              "  1013,\n",
              "  1028,\n",
              "  1026,\n",
              "  7987,\n",
              "  1013,\n",
              "  1028,\n",
              "  1045,\n",
              "  2079,\n",
              "  4012,\n",
              "  3549,\n",
              "  2094,\n",
              "  1996,\n",
              "  16587,\n",
              "  2005,\n",
              "  1996,\n",
              "  2755,\n",
              "  2008,\n",
              "  2151,\n",
              "  3348,\n",
              "  3491,\n",
              "  1999,\n",
              "  1996,\n",
              "  2143,\n",
              "  2003,\n",
              "  3491,\n",
              "  2005,\n",
              "  6018,\n",
              "  5682,\n",
              "  2738,\n",
              "  2084,\n",
              "  2074,\n",
              "  2000,\n",
              "  5213,\n",
              "  2111,\n",
              "  1998,\n",
              "  2191,\n",
              "  2769,\n",
              "  2000,\n",
              "  2022,\n",
              "  3491,\n",
              "  1999,\n",
              "  26932,\n",
              "  12370,\n",
              "  1999,\n",
              "  2637,\n",
              "  1012,\n",
              "  1045,\n",
              "  2572,\n",
              "  8025,\n",
              "  1011,\n",
              "  3756,\n",
              "  2003,\n",
              "  1037,\n",
              "  2204,\n",
              "  2143,\n",
              "  2005,\n",
              "  3087,\n",
              "  5782,\n",
              "  2000,\n",
              "  2817,\n",
              "  1996,\n",
              "  6240,\n",
              "  1998,\n",
              "  14629,\n",
              "  1006,\n",
              "  2053,\n",
              "  26136,\n",
              "  3832,\n",
              "  1007,\n",
              "  1997,\n",
              "  4467,\n",
              "  5988,\n",
              "  1012,\n",
              "  2021,\n",
              "  2428,\n",
              "  1010,\n",
              "  2023,\n",
              "  2143,\n",
              "  2987,\n",
              "  1005,\n",
              "  1056,\n",
              "  2031,\n",
              "  2172,\n",
              "  1997,\n",
              "  1037,\n",
              "  5436,\n",
              "  1012,\n",
              "  102,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0],\n",
              " 'attention_mask': [1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0]}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "-4lY_LHTXgpa",
        "outputId": "f96b891b-f4ed-4b58-e94f-ca9cdc42de15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label  \\\n",
              "0     I rented I AM CURIOUS-YELLOW from my video sto...      0   \n",
              "1     \"I Am Curious: Yellow\" is a risible and preten...      0   \n",
              "2     If only to avoid making this type of film in t...      0   \n",
              "3     This film was probably inspired by Godard's Ma...      0   \n",
              "4     Oh, brother...after hearing about this ridicul...      0   \n",
              "...                                                 ...    ...   \n",
              "3995  A hit at the time but now better categorised a...      1   \n",
              "3996  I love this movie like no other. Another time ...      1   \n",
              "3997  This film and it's sequel Barry Mckenzie holds...      1   \n",
              "3998  'The Adventures Of Barry McKenzie' started lif...      1   \n",
              "3999  The story centers around Barry McKenzie who mu...      1   \n",
              "\n",
              "                                              input_ids  \\\n",
              "0     [101, 1045, 12524, 1045, 2572, 8025, 1011, 375...   \n",
              "1     [101, 1000, 1045, 2572, 8025, 1024, 3756, 1000...   \n",
              "2     [101, 2065, 2069, 2000, 4468, 2437, 2023, 2828...   \n",
              "3     [101, 2023, 2143, 2001, 2763, 4427, 2011, 2643...   \n",
              "4     [101, 2821, 1010, 2567, 1012, 1012, 1012, 2044...   \n",
              "...                                                 ...   \n",
              "3995  [101, 1037, 2718, 2012, 1996, 2051, 2021, 2085...   \n",
              "3996  [101, 1045, 2293, 2023, 3185, 2066, 2053, 2060...   \n",
              "3997  [101, 2023, 2143, 1998, 2009, 1005, 1055, 8297...   \n",
              "3998  [101, 1005, 1996, 7357, 1997, 6287, 18506, 100...   \n",
              "3999  [101, 1996, 2466, 6401, 2105, 6287, 18506, 204...   \n",
              "\n",
              "                                         attention_mask  \n",
              "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "...                                                 ...  \n",
              "3995  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "3996  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "3997  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "3998  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "3999  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "\n",
              "[4000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-735179f3-0215-4f96-8ac6-05b942eb0f97\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
              "      <td>0</td>\n",
              "      <td>[101, 1045, 12524, 1045, 2572, 8025, 1011, 375...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
              "      <td>0</td>\n",
              "      <td>[101, 1000, 1045, 2572, 8025, 1024, 3756, 1000...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If only to avoid making this type of film in t...</td>\n",
              "      <td>0</td>\n",
              "      <td>[101, 2065, 2069, 2000, 4468, 2437, 2023, 2828...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This film was probably inspired by Godard's Ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>[101, 2023, 2143, 2001, 2763, 4427, 2011, 2643...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
              "      <td>0</td>\n",
              "      <td>[101, 2821, 1010, 2567, 1012, 1012, 1012, 2044...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>A hit at the time but now better categorised a...</td>\n",
              "      <td>1</td>\n",
              "      <td>[101, 1037, 2718, 2012, 1996, 2051, 2021, 2085...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>I love this movie like no other. Another time ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[101, 1045, 2293, 2023, 3185, 2066, 2053, 2060...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>This film and it's sequel Barry Mckenzie holds...</td>\n",
              "      <td>1</td>\n",
              "      <td>[101, 2023, 2143, 1998, 2009, 1005, 1055, 8297...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>'The Adventures Of Barry McKenzie' started lif...</td>\n",
              "      <td>1</td>\n",
              "      <td>[101, 1005, 1996, 7357, 1997, 6287, 18506, 100...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>The story centers around Barry McKenzie who mu...</td>\n",
              "      <td>1</td>\n",
              "      <td>[101, 1996, 2466, 6401, 2105, 6287, 18506, 204...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-735179f3-0215-4f96-8ac6-05b942eb0f97')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-735179f3-0215-4f96-8ac6-05b942eb0f97 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-735179f3-0215-4f96-8ac6-05b942eb0f97');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f13739b5-b351-46b5-9ef4-bb9dfe350134\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f13739b5-b351-46b5-9ef4-bb9dfe350134')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f13739b5-b351-46b5-9ef4-bb9dfe350134 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 4000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3995,\n        \"samples\": [\n          \"Okay, if you've seen The Ring, you've basically seen The Grudge. It's trying to be scary by just having freaky camera work and loud sounds, but it fails miserably. The plot, if you can call it that, is weak and rather full of holes, for instance, how would the care center have known that Yoko didn't show up for work when the people who lived in the house were not there? And it's not really clear what Bill Pullman's character had to do with anything. He just kind of came out of nowhere to advance the plot. It didn't make a lot of sense what happened to the original family. Who was hanging in the room, the little boy or the dad? And was Yoko alive or dead when the care center guy found her? There were too many unanswered questions and I was too bored to think about it more.\",\n          \"Paris is the place to be to enjoy beautiful art and music, and to fall madly in love - as is the case in this film. Boy meets girl, they fall in love, but something stands in their way of eternal happiness, the classic story.<br /><br />The wonderful music of George Gerschwin complements the great dancing by Gene Kelly and Leslie Caron. \\\"An American in Paris\\\" is a humorous, light-hearted, loving film well worth watching.<br /><br />8/10<br /><br />\",\n          \"Takashi Shimizu had a great opportunity with a remake of his original film Ju-On The Grudge. While I haven't seen that film, I would have to wager that there's more imagination and originality (or some rip-off originality, in other words skill with known tropes of the Japanese ghost movie) than in his own directed remake. Maybe the script was written to somehow have some kind of warped appeal, or I would guess accessibility, for an American audience. What starts off with some potential - the hint of something very screwed up going on with Bill Pullman's sudden movement - just goes into a total jumble. And as a horror movie? Gimme a break.<br /><br />Tension could have been built on the situation - a nurse going to take care of a disturbed woman in a house that is haunted - but he undercuts everything he wants to get his audience to feel. Scares? How's about some music timed just so you know when exactly to expect something. A black cat? Yeah, why not just make the ghost-boy thing sound like a cat for creepiness which, in effect, is only creepy if you want cats. Plot? Why not just shuffle between past and present without any semblance of an actual flow of how a story could be told (meaning, while the flashbacks are inserted and are meant to be organic with the story overall, they aren't), or for that matter have us care about ANYONE in the cast.<br /><br />By the time the characters, or those that are there for exposition, get around to telling us what is going on or whatever, there's little point to care. The film-making is shoddy (i.e. the 180 degree rule is broken many times over and not in a forgivable or intriguing way), and the performances are wooden even when looking frightened or shocked (Gellar especially is disappointing, but Pullman, who shows up later after his first scene, is sorely miscast). Even when Shimizu tries for some average old \\\"Boo\\\" scares, like when the woman is in the office building and chased by the Grudge ghost, it's still silly. Just watch when she's going on that elevator and the ghost is in the background of shots. Either you'll go with it, and if so more power to you, or you'll laugh hysterically at the results. Count me in the latter.<br /><br />I'm not totally sure where this project went wrong - was it Shimizu having to retool it for the studios, or him not giving enough leeway with his revamp of his vision? Or maybe Raimi had some say in it and made things more confusing and/or dull than they would be with someone else. The Grudge gives us a lot of information that doesn't make sense or at the least give us some horror-fodder to chew on. It's cineplex trash of a sad order.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_ids\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attention_mask\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(enc_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACNK9ZQKD4mt"
      },
      "source": [
        "## Preparing training settings with TrainingArguments and Trainer class\n",
        "\n",
        "TrainingArguments is the subset of the arguments we use in our example scripts which relate to the training loop itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "OZD1jnhFWEd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "042514a5-5263-498d-a76e-a58562d230ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainingArguments(\n",
              "_n_gpu=1,\n",
              "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
              "adafactor=False,\n",
              "adam_beta1=0.9,\n",
              "adam_beta2=0.999,\n",
              "adam_epsilon=1e-08,\n",
              "auto_find_batch_size=False,\n",
              "average_tokens_across_devices=False,\n",
              "batch_eval_metrics=False,\n",
              "bf16=False,\n",
              "bf16_full_eval=False,\n",
              "data_seed=None,\n",
              "dataloader_drop_last=False,\n",
              "dataloader_num_workers=0,\n",
              "dataloader_persistent_workers=False,\n",
              "dataloader_pin_memory=True,\n",
              "dataloader_prefetch_factor=None,\n",
              "ddp_backend=None,\n",
              "ddp_broadcast_buffers=None,\n",
              "ddp_bucket_cap_mb=None,\n",
              "ddp_find_unused_parameters=None,\n",
              "ddp_timeout=1800,\n",
              "debug=[],\n",
              "deepspeed=None,\n",
              "disable_tqdm=False,\n",
              "dispatch_batches=None,\n",
              "do_eval=True,\n",
              "do_predict=False,\n",
              "do_train=True,\n",
              "eval_accumulation_steps=None,\n",
              "eval_delay=0,\n",
              "eval_do_concat_batches=True,\n",
              "eval_on_start=False,\n",
              "eval_steps=50,\n",
              "eval_strategy=IntervalStrategy.STEPS,\n",
              "eval_use_gather_object=False,\n",
              "evaluation_strategy=steps,\n",
              "fp16=True,\n",
              "fp16_backend=auto,\n",
              "fp16_full_eval=False,\n",
              "fp16_opt_level=O1,\n",
              "fsdp=[],\n",
              "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
              "fsdp_min_num_params=0,\n",
              "fsdp_transformer_layer_cls_to_wrap=None,\n",
              "full_determinism=False,\n",
              "gradient_accumulation_steps=1,\n",
              "gradient_checkpointing=False,\n",
              "gradient_checkpointing_kwargs=None,\n",
              "greater_is_better=None,\n",
              "group_by_length=False,\n",
              "half_precision_backend=auto,\n",
              "hub_always_push=False,\n",
              "hub_model_id=None,\n",
              "hub_private_repo=None,\n",
              "hub_strategy=HubStrategy.EVERY_SAVE,\n",
              "hub_token=<HUB_TOKEN>,\n",
              "ignore_data_skip=False,\n",
              "include_for_metrics=[],\n",
              "include_inputs_for_metrics=False,\n",
              "include_num_input_tokens_seen=False,\n",
              "include_tokens_per_second=False,\n",
              "jit_mode_eval=False,\n",
              "label_names=None,\n",
              "label_smoothing_factor=0.0,\n",
              "learning_rate=5e-05,\n",
              "length_column_name=length,\n",
              "load_best_model_at_end=False,\n",
              "local_rank=0,\n",
              "log_level=passive,\n",
              "log_level_replica=warning,\n",
              "log_on_each_node=True,\n",
              "logging_dir=./logs,\n",
              "logging_first_step=False,\n",
              "logging_nan_inf_filter=True,\n",
              "logging_steps=50,\n",
              "logging_strategy=IntervalStrategy.STEPS,\n",
              "lr_scheduler_kwargs={},\n",
              "lr_scheduler_type=SchedulerType.LINEAR,\n",
              "max_grad_norm=1.0,\n",
              "max_steps=-1,\n",
              "metric_for_best_model=None,\n",
              "mp_parameters=,\n",
              "neftune_noise_alpha=None,\n",
              "no_cuda=False,\n",
              "num_train_epochs=3,\n",
              "optim=OptimizerNames.ADAMW_TORCH,\n",
              "optim_args=None,\n",
              "optim_target_modules=None,\n",
              "output_dir=./MyIMDBModel,\n",
              "overwrite_output_dir=False,\n",
              "past_index=-1,\n",
              "per_device_eval_batch_size=64,\n",
              "per_device_train_batch_size=32,\n",
              "prediction_loss_only=False,\n",
              "push_to_hub=False,\n",
              "push_to_hub_model_id=None,\n",
              "push_to_hub_organization=None,\n",
              "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
              "ray_scope=last,\n",
              "remove_unused_columns=True,\n",
              "report_to=[],\n",
              "restore_callback_states_from_checkpoint=False,\n",
              "resume_from_checkpoint=None,\n",
              "run_name=./MyIMDBModel,\n",
              "save_on_each_node=False,\n",
              "save_only_model=False,\n",
              "save_safetensors=True,\n",
              "save_steps=500,\n",
              "save_strategy=SaveStrategy.EPOCH,\n",
              "save_total_limit=None,\n",
              "seed=42,\n",
              "skip_memory_metrics=True,\n",
              "split_batches=None,\n",
              "tf32=None,\n",
              "torch_compile=False,\n",
              "torch_compile_backend=None,\n",
              "torch_compile_mode=None,\n",
              "torch_empty_cache_steps=None,\n",
              "torchdynamo=None,\n",
              "tpu_metrics_debug=False,\n",
              "tpu_num_cores=None,\n",
              "use_cpu=False,\n",
              "use_ipex=False,\n",
              "use_legacy_prediction_loop=False,\n",
              "use_liger_kernel=False,\n",
              "use_mps_device=False,\n",
              "warmup_ratio=0.0,\n",
              "warmup_steps=100,\n",
              "weight_decay=0.01,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "from torch import cuda\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    # The output directory where the model predictions and checkpoints will be written\n",
        "    output_dir=\"./MyIMDBModel\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    #  The number of epochs, defaults to 3.0\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    # Number of steps used for a linear warmup\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    logging_strategy=\"steps\",\n",
        "    # TensorBoard log directory\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    # other options : no, steps\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=cuda.is_available(),\n",
        "    report_to=[],\n",
        ")\n",
        "training_args"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUn5uFHkbPEb"
      },
      "source": [
        "Let's design our evaluation metrics as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "8Ct3v6RZZSmj"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, preds, average=\"macro\"\n",
        "    )\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"Accuracy\": acc, \"F1\": f1, \"Precision\": precision, \"Recall\": recall}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztS1YQcqWEgZ",
        "outputId": "9ce79b81-9e8b-46a6-baa0-4af4d77f6d63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<transformers.trainer.Trainer at 0x7899b7d36310>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    # the pre-trained model that will be fine-tuned\n",
        "    model=model,\n",
        "    # training arguments that we defined above\n",
        "    args=training_args,\n",
        "    # training and validation dataset\n",
        "    train_dataset=enc_train,\n",
        "    eval_dataset=enc_val,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "zF7FUYOzWFFT",
        "outputId": "c75f38a5-2a68-46bc-e126-5bf91646d0d5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [375/375 03:05, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.607900</td>\n",
              "      <td>0.385553</td>\n",
              "      <td>0.852000</td>\n",
              "      <td>0.851429</td>\n",
              "      <td>0.857497</td>\n",
              "      <td>0.852000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.339300</td>\n",
              "      <td>0.433839</td>\n",
              "      <td>0.828000</td>\n",
              "      <td>0.824950</td>\n",
              "      <td>0.852573</td>\n",
              "      <td>0.828000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.278200</td>\n",
              "      <td>0.305051</td>\n",
              "      <td>0.885000</td>\n",
              "      <td>0.884723</td>\n",
              "      <td>0.888733</td>\n",
              "      <td>0.885000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.199600</td>\n",
              "      <td>0.293084</td>\n",
              "      <td>0.897000</td>\n",
              "      <td>0.896710</td>\n",
              "      <td>0.901511</td>\n",
              "      <td>0.897000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.208700</td>\n",
              "      <td>0.316819</td>\n",
              "      <td>0.886000</td>\n",
              "      <td>0.885531</td>\n",
              "      <td>0.892430</td>\n",
              "      <td>0.886000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.096400</td>\n",
              "      <td>0.366476</td>\n",
              "      <td>0.888000</td>\n",
              "      <td>0.887899</td>\n",
              "      <td>0.889402</td>\n",
              "      <td>0.888000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.105900</td>\n",
              "      <td>0.336165</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.899998</td>\n",
              "      <td>0.900026</td>\n",
              "      <td>0.900000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "results = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_LLlhK5i69Q"
      },
      "source": [
        "* For small portion\n",
        "\n",
        "We have 4K training examples and the batch size is 32, which means each epoch takes 4k/32 = 125 steps. For 3 epoc, this will have 375 steps as wee see in the output.\n",
        "\n",
        "* For full dataset\n",
        "\n",
        "We have 25K training  examples with the batch size pf 32, so we will have 25K/32 ~=782 (roughly) steps. for 3 epoch we will have 2346 steps to run as seen in the progress bar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWmDkDVWIzzO"
      },
      "source": [
        "Trainer model keeps the best model at the end. Lets evaluate the model on the train/test/validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "MfBHiik5XMmf",
        "outputId": "14708295-8957-43a1-a966-82d38218a05e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='95' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:23]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       eval_loss  eval_Accuracy   eval_F1  eval_Precision  eval_Recall\n",
              "train   0.047899          0.989  0.989000        0.989018        0.989\n",
              "val     0.335838          0.895  0.894999        0.895014        0.895\n",
              "test    0.252059          0.919  0.918982        0.919377        0.919"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fec0d114-55c1-4d45-9fb5-00f2c074c2b2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eval_loss</th>\n",
              "      <th>eval_Accuracy</th>\n",
              "      <th>eval_F1</th>\n",
              "      <th>eval_Precision</th>\n",
              "      <th>eval_Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>0.047899</td>\n",
              "      <td>0.989</td>\n",
              "      <td>0.989000</td>\n",
              "      <td>0.989018</td>\n",
              "      <td>0.989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>0.335838</td>\n",
              "      <td>0.895</td>\n",
              "      <td>0.894999</td>\n",
              "      <td>0.895014</td>\n",
              "      <td>0.895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>0.252059</td>\n",
              "      <td>0.919</td>\n",
              "      <td>0.918982</td>\n",
              "      <td>0.919377</td>\n",
              "      <td>0.919</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fec0d114-55c1-4d45-9fb5-00f2c074c2b2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fec0d114-55c1-4d45-9fb5-00f2c074c2b2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fec0d114-55c1-4d45-9fb5-00f2c074c2b2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-be50b371-759e-422f-959b-46cf6cfd2745\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-be50b371-759e-422f-959b-46cf6cfd2745')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-be50b371-759e-422f-959b-46cf6cfd2745 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"eval_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14810420519554998,\n        \"min\": 0.04789910838007927,\n        \"max\": 0.33583831787109375,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.04789910838007927,\n          0.33583831787109375,\n          0.25205862522125244\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04883987441971295,\n        \"min\": 0.895,\n        \"max\": 0.989,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.989,\n          0.895,\n          0.919\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04884306203753255,\n        \"min\": 0.8949990549914949,\n        \"max\": 0.9889999009991091,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9889999009991091,\n          0.8949990549914949,\n          0.9189817708984522\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.048785167226577546,\n        \"min\": 0.8950142205119385,\n        \"max\": 0.9890176046337669,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9890176046337669,\n          0.8950142205119385,\n          0.9193774396957262\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04883987441971295,\n        \"min\": 0.895,\n        \"max\": 0.989,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.989,\n          0.895,\n          0.919\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "q = [trainer.evaluate(eval_dataset=data) for data in [enc_train, enc_val, enc_test]]\n",
        "pd.DataFrame(q, index=[\"train\", \"val\", \"test\"]).iloc[:, :5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQRdl3cfc53K",
        "outputId": "c36fc93b-cf40-4e70-9868-918d7ae89e16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('MyBestIMDBModel/tokenizer_config.json',\n",
              " 'MyBestIMDBModel/special_tokens_map.json',\n",
              " 'MyBestIMDBModel/vocab.txt',\n",
              " 'MyBestIMDBModel/added_tokens.json',\n",
              " 'MyBestIMDBModel/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "# saving the best fine-tuned model & tokenizer\n",
        "model_save_path = \"MyBestIMDBModel\"\n",
        "trainer.save_model(model_save_path)\n",
        "tokenizer.save_pretrained(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tree -a \"/content/drive/MyDrive/Colab Notebooks/MyBert\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t4_Ylac4cSF",
        "outputId": "440494e0-49e3-4cc9-ded8-48aa329d8eef"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34m/content/drive/MyDrive/Colab Notebooks/MyBert\u001b[0m\n",
            "├── \u001b[01;34mMyBestIMDBModel\u001b[0m\n",
            "│   ├── \u001b[00mconfig.json\u001b[0m\n",
            "│   ├── \u001b[00mmodel.safetensors\u001b[0m\n",
            "│   ├── \u001b[00mspecial_tokens_map.json\u001b[0m\n",
            "│   ├── \u001b[00mtokenizer_config.json\u001b[0m\n",
            "│   ├── \u001b[00mtokenizer.json\u001b[0m\n",
            "│   ├── \u001b[00mtraining_args.bin\u001b[0m\n",
            "│   └── \u001b[00mvocab.txt\u001b[0m\n",
            "└── \u001b[01;34mMyIMDBModel\u001b[0m\n",
            "    ├── \u001b[01;34mcheckpoint-125\u001b[0m\n",
            "    │   ├── \u001b[00mconfig.json\u001b[0m\n",
            "    │   ├── \u001b[00mmodel.safetensors\u001b[0m\n",
            "    │   ├── \u001b[00moptimizer.pt\u001b[0m\n",
            "    │   ├── \u001b[00mrng_state.pth\u001b[0m\n",
            "    │   ├── \u001b[00mscheduler.pt\u001b[0m\n",
            "    │   ├── \u001b[00mtrainer_state.json\u001b[0m\n",
            "    │   └── \u001b[00mtraining_args.bin\u001b[0m\n",
            "    ├── \u001b[01;34mcheckpoint-250\u001b[0m\n",
            "    │   ├── \u001b[00mconfig.json\u001b[0m\n",
            "    │   ├── \u001b[00mmodel.safetensors\u001b[0m\n",
            "    │   ├── \u001b[00moptimizer.pt\u001b[0m\n",
            "    │   ├── \u001b[00mrng_state.pth\u001b[0m\n",
            "    │   ├── \u001b[00mscheduler.pt\u001b[0m\n",
            "    │   ├── \u001b[00mtrainer_state.json\u001b[0m\n",
            "    │   └── \u001b[00mtraining_args.bin\u001b[0m\n",
            "    └── \u001b[01;34mcheckpoint-375\u001b[0m\n",
            "        ├── \u001b[00mconfig.json\u001b[0m\n",
            "        ├── \u001b[00mmodel.safetensors\u001b[0m\n",
            "        ├── \u001b[00moptimizer.pt\u001b[0m\n",
            "        ├── \u001b[00mrng_state.pth\u001b[0m\n",
            "        ├── \u001b[00mscheduler.pt\u001b[0m\n",
            "        ├── \u001b[00mtrainer_state.json\u001b[0m\n",
            "        └── \u001b[00mtraining_args.bin\u001b[0m\n",
            "\n",
            "5 directories, 28 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2a3rNrLfHQ3"
      },
      "outputs": [],
      "source": [
        "def get_prediction(text):\n",
        "    inputs = tokenizer(\n",
        "        text, padding=True, truncation=True, max_length=250, return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "    outputs = model(inputs[\"input_ids\"].to(device), inputs[\"attention_mask\"].to(device))\n",
        "    probs = outputs[0].softmax(1)\n",
        "    return probs, probs.argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nSJDJ5mfTdu"
      },
      "outputs": [],
      "source": [
        "model.to(device)\n",
        "text = \"I didn't like the movie since it bored me \"\n",
        "get_prediction(text)[1].item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEPQzT4UDk7B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze4nteT-mCUC"
      },
      "source": [
        "Use the model with pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQ7sVE4blgzX"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    pipeline,\n",
        "    DistilBertForSequenceClassification,\n",
        "    DistilBertTokenizerFast,\n",
        ")\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"MyBestIMDBModel\")\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\"MyBestIMDBModel\")\n",
        "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
        "nlp(\"the movie was very impressive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Jv-X4pN3H9Y"
      },
      "outputs": [],
      "source": [
        "nlp(\"the script of the picture was very poor\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPiDrENVJ42j"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8ca51ba617f840c185453cb68d98f5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a6bed2f9a7e41b0bc107df622b785a0",
              "IPY_MODEL_7d5d85b9c4754cbeac195d6b34771fa5",
              "IPY_MODEL_05853654c2fa4eb38560041b617c3335"
            ],
            "layout": "IPY_MODEL_bec7decff2ef49daace63d161a5baeb3"
          }
        },
        "6a6bed2f9a7e41b0bc107df622b785a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6d42e26f7cc4ab0bfd31ec1d0539c35",
            "placeholder": "​",
            "style": "IPY_MODEL_82fbc94f764f4038816e619ea4a19ef4",
            "value": "Map: 100%"
          }
        },
        "7d5d85b9c4754cbeac195d6b34771fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_952c865c7c844a9090b83fcb9207f10c",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64eacb2d9c1342198c69f4ad6d257df9",
            "value": 1000
          }
        },
        "05853654c2fa4eb38560041b617c3335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98cb9bf77139496c9eec835f98f13a1c",
            "placeholder": "​",
            "style": "IPY_MODEL_dd5a789f66d6469b95ac69c599afcd6f",
            "value": " 1000/1000 [00:00&lt;00:00, 1166.64 examples/s]"
          }
        },
        "bec7decff2ef49daace63d161a5baeb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6d42e26f7cc4ab0bfd31ec1d0539c35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82fbc94f764f4038816e619ea4a19ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "952c865c7c844a9090b83fcb9207f10c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64eacb2d9c1342198c69f4ad6d257df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98cb9bf77139496c9eec835f98f13a1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd5a789f66d6469b95ac69c599afcd6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}