{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdd1b6iEGeMp"
      },
      "source": [
        "# Fine-Tuning Language Models for Text Classification\n",
        "用于文本分类的微调语言模型\n",
        "\n",
        "##### Fine-Tuning with Native Pytorch\n",
        "\n",
        "## Preparation for Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gorSCX38XGd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "#  挂载 google 云盘\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "print(os.getcwd())  # /content\n",
        "\n",
        "# print(os.listdir(\"/content/drive/MyDrive/\"))\n",
        "\n",
        "# print(os.listdir(\"/content/drive/MyDrive/Colab Notebooks\"))\n",
        "\n",
        "# if os.getcwd() != \"/content/drive/MyDrive\":\n",
        "#     os.chdir(\"/content/drive/MyDrive\")\n",
        "\n",
        "# print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suxP2W--_99L"
      },
      "outputs": [],
      "source": [
        "# 提前将 requirements.txt 放在 google 云盘上\n",
        "!pip install -r /content/drive/MyDrive/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBxjrjcf_-Aa",
        "outputId": "0d2a330f-4aa2-46f8-e49c-aafd495e01ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ch05b\n"
          ]
        }
      ],
      "source": [
        "subdir = \"ch05b\"\n",
        "work_path = \"/content/drive/MyDrive/\" + subdir\n",
        "if not os.path.exists(work_path):\n",
        "    os.mkdir(work_path)\n",
        "os.chdir(work_path)\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxqtGMP__-Dn",
        "outputId": "36834e51-7f82-414b-812c-f7ad1f1b10aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tree is already the newest version (2.0.2-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "\u001b[01;34m./\u001b[0m\n",
            "\n",
            "0 directories, 0 files\n"
          ]
        }
      ],
      "source": [
        "!apt-get install tree && tree -a \"./\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "087OXCoeN-Zf"
      },
      "source": [
        "## Loading pre-trained model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrjheWzxvQf2",
        "outputId": "48d36354-8ff4-4026-c9c9-e73482e30721"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import DistilBertForSequenceClassification\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h7TBrdyTjpJ",
        "outputId": "8963dd83-262b-4a73-abf2-a88980f7e3af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'DistilBertTokenizerFast'.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DistilBertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
              "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizerFast\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75afLI_FvQi7",
        "outputId": "f5fab357-5a10-48ef-be7d-87fd2a3ddc6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AdamW (\n",
              "Parameter Group 0\n",
              "    betas: (0.9, 0.999)\n",
              "    correct_bias: True\n",
              "    eps: 1e-06\n",
              "    lr: 0.001\n",
              "    weight_decay: 0.0\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=1e-3)\n",
        "optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKX6Ixw6BYgo"
      },
      "source": [
        "### 验证"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NEdeBUh-fqW",
        "outputId": "0fcd6a04-6a78-467f-9870-25e7034bc45c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "texts: ['this is a good example', 'this is a bad example', 'this is a good one']\n",
            "encoding: {'input_ids': tensor([[ 101, 2023, 2003, 1037, 2204, 2742,  102],\n",
            "        [ 101, 2023, 2003, 1037, 2919, 2742,  102],\n",
            "        [ 101, 2023, 2003, 1037, 2204, 2028,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1]])}\n",
            "input_ids: tensor([[ 101, 2023, 2003, 1037, 2204, 2742,  102],\n",
            "        [ 101, 2023, 2003, 1037, 2919, 2742,  102],\n",
            "        [ 101, 2023, 2003, 1037, 2204, 2028,  102]])\n",
            "input_ids: torch.Size([3, 7])\n",
            "attention_mask: tensor([[1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1]])\n",
            "attention_mask: torch.Size([3, 7])\n",
            "labels: tensor([[1, 0, 1]])\n",
            "labels: torch.Size([1, 3])\n"
          ]
        }
      ],
      "source": [
        "# one step forward\n",
        "import torch\n",
        "\n",
        "texts = [\"this is a good example\", \"this is a bad example\", \"this is a good one\"]\n",
        "print(\"texts:\", texts)\n",
        "encoding = tokenizer(\n",
        "    texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512\n",
        ")\n",
        "print(\"encoding:\", encoding)\n",
        "\n",
        "input_ids = encoding[\"input_ids\"]\n",
        "attention_mask = encoding[\"attention_mask\"]\n",
        "print(\"input_ids:\", input_ids)\n",
        "print(\"input_ids:\", input_ids.shape)\n",
        "print(\"attention_mask:\", attention_mask)\n",
        "print(\"attention_mask:\", attention_mask.shape)\n",
        "\n",
        "labels = [1, 0, 1]\n",
        "labels = torch.tensor(labels).unsqueeze(0)\n",
        "print(\"labels:\", labels)\n",
        "print(\"labels:\", labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLHyHE_4vQo0",
        "outputId": "2a86aafc-cc80-4ab7-b8d0-6c0a957b76c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SequenceClassifierOutput(loss=tensor(0.6774, grad_fn=<NllLossBackward0>), logits=tensor([[-0.0815,  0.0293],\n",
              "        [-0.0779,  0.0238],\n",
              "        [-0.0296,  0.0636]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jlLsQVMOaCR",
        "outputId": "92054e9f-f182-4c2f-cbc4-838454b159e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[-0.0815,  0.0293],\n",
              "         [-0.0779,  0.0238],\n",
              "         [-0.0296,  0.0636]], grad_fn=<AddmmBackward0>),\n",
              " torch.Size([3, 2]))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs.logits, outputs.logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMwRgtXovQrk",
        "outputId": "2266b28b-da1a-4393-9685-a10683d8296c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(0.6774, grad_fn=<NllLossBackward0>), torch.Size([]))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss = outputs.loss\n",
        "loss, loss.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DnbXt46DZRmF"
      },
      "outputs": [],
      "source": [
        "loss.backward()\n",
        "optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrtXFsuevQyH",
        "outputId": "f04df84b-0bdd-4490-c2cb-1e852c672b0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(SequenceClassifierOutput(loss=None, logits=tensor([[-0.5801,  0.6060],\n",
              "         [-0.5247,  0.5688],\n",
              "         [-0.5666,  0.5986]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None),\n",
              " torch.Size([3, 2]))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Manually calculate loss\n",
        "from torch.nn import functional\n",
        "\n",
        "labels = torch.tensor([1, 0, 1])\n",
        "outputs = model(input_ids, attention_mask=attention_mask)\n",
        "outputs, outputs.logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj0qMlTIxa8L",
        "outputId": "f14f9626-b976-44c6-8610-8f1ad0f52cc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(0.6401, grad_fn=<NllLossBackward0>), torch.Size([]))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss = functional.cross_entropy(outputs.logits, labels)\n",
        "loss, loss.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YAZN5BUpxa-W"
      },
      "outputs": [],
      "source": [
        "loss.backward()\n",
        "optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHFl5T_aOJik"
      },
      "source": [
        "## Training the model from entire dataset with Native PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_hoE8Q7WmIK2"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9FCV-5oQcug",
        "outputId": "78321428-1126-4392-a365-d641be27e517"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertForSequenceClassification\n",
        "from transformers import DistilBertTokenizerFast\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GZc-IP_qOPr",
        "outputId": "116b3ec6-1876-4302-9b40-455133f166fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sst2: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['sentence', 'label', 'idx'],\n",
            "        num_rows: 67349\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['sentence', 'label', 'idx'],\n",
            "        num_rows: 872\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['sentence', 'label', 'idx'],\n",
            "        num_rows: 1821\n",
            "    })\n",
            "})\n",
            "metric: EvaluationModule(name: \"glue\", module_type: \"metric\", features: {'predictions': Value(dtype='int64', id=None), 'references': Value(dtype='int64', id=None)}, usage: \"\"\"\n",
            "Compute GLUE evaluation metric associated to each GLUE dataset.\n",
            "Args:\n",
            "    predictions: list of predictions to score.\n",
            "        Each translation should be tokenized into a list of tokens.\n",
            "    references: list of lists of references for each translation.\n",
            "        Each reference should be tokenized into a list of tokens.\n",
            "Returns: depending on the GLUE subset, one or several of:\n",
            "    \"accuracy\": Accuracy\n",
            "    \"f1\": F1 score\n",
            "    \"pearson\": Pearson Correlation\n",
            "    \"spearmanr\": Spearman Correlation\n",
            "    \"matthews_correlation\": Matthew Correlation\n",
            "Examples:\n",
            "\n",
            "    >>> glue_metric = evaluate.load('glue', 'sst2')  # 'sst2' or any of [\"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]\n",
            "    >>> references = [0, 1]\n",
            "    >>> predictions = [0, 1]\n",
            "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
            "    >>> print(results)\n",
            "    {'accuracy': 1.0}\n",
            "\n",
            "    >>> glue_metric = evaluate.load('glue', 'mrpc')  # 'mrpc' or 'qqp'\n",
            "    >>> references = [0, 1]\n",
            "    >>> predictions = [0, 1]\n",
            "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
            "    >>> print(results)\n",
            "    {'accuracy': 1.0, 'f1': 1.0}\n",
            "\n",
            "    >>> glue_metric = evaluate.load('glue', 'stsb')\n",
            "    >>> references = [0., 1., 2., 3., 4., 5.]\n",
            "    >>> predictions = [0., 1., 2., 3., 4., 5.]\n",
            "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
            "    >>> print({\"pearson\": round(results[\"pearson\"], 2), \"spearmanr\": round(results[\"spearmanr\"], 2)})\n",
            "    {'pearson': 1.0, 'spearmanr': 1.0}\n",
            "\n",
            "    >>> glue_metric = evaluate.load('glue', 'cola')\n",
            "    >>> references = [0, 1]\n",
            "    >>> predictions = [0, 1]\n",
            "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
            "    >>> print(results)\n",
            "    {'matthews_correlation': 1.0}\n",
            "\"\"\", stored examples: 0)\n"
          ]
        }
      ],
      "source": [
        "# import datasets\n",
        "from datasets import load_dataset\n",
        "from evaluate import load\n",
        "\n",
        "sst2 = load_dataset(\"glue\", \"sst2\")\n",
        "print(\"sst2:\", sst2)\n",
        "\n",
        "metric = load(\"glue\", \"sst2\")\n",
        "print(\"metric:\", metric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Q0u7JTJZePSD"
      },
      "outputs": [],
      "source": [
        "texts = sst2[\"train\"][\"sentence\"]\n",
        "labels = sst2[\"train\"][\"label\"]\n",
        "val_texts = sst2[\"validation\"][\"sentence\"]\n",
        "val_labels = sst2[\"validation\"][\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qz_bGusOh7V",
        "outputId": "2acdbca4-d020-445b-e298-b363fc984c66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(67349, 67349, 872, 872)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(texts), len(labels), len(val_texts), len(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QApRHkjdPY9c",
        "outputId": "d0c089f1-af3e-40bf-fe7d-30a9c21a3bc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sentence': 'hide new secretions from the parental units ',\n",
              " 'label': 0,\n",
              " 'idx': 0}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sst2[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PJUHozzzbxg1"
      },
      "outputs": [],
      "source": [
        "# I will take small portion\n",
        "K = 10000\n",
        "train_dataset = MyDataset(\n",
        "    tokenizer(texts[:K], truncation=True, padding=True), labels[:K]\n",
        ")\n",
        "val_dataset = MyDataset(tokenizer(val_texts, truncation=True, padding=True), val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTTu1fmIxx8w",
        "outputId": "494fd9bb-0094-49bf-9c7d-b2324c9e3de1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda\n",
            "epoch 0: {'accuracy': 0.8853211009174312}\n",
            "epoch 1: {'accuracy': 0.8704128440366973}\n",
            "epoch 2: {'accuracy': 0.8956422018348624}\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"device:\", device)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "for epoch in range(3):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    model.eval()\n",
        "    for batch in val_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        predictions = outputs.logits.argmax(dim=-1)\n",
        "        metric.add_batch(\n",
        "            predictions=predictions,\n",
        "            references=batch[\"labels\"],\n",
        "        )\n",
        "    eval_metric = metric.compute()\n",
        "    print(f\"epoch {epoch}: {eval_metric}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "DjrjOM3rszDB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
