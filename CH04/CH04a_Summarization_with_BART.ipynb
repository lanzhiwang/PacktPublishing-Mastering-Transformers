{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrJgwl0tzcWv"
      },
      "source": [
        "# Autoregressive and Other Language Models\n",
        "自回归和其他语言模型\n",
        "\n",
        "## Preparation for Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A93n3UPhzTRQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "#  挂载 google 云盘\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "print(os.getcwd())  # /content\n",
        "\n",
        "# print(os.listdir(\"/content/drive/MyDrive/\"))\n",
        "\n",
        "# print(os.listdir(\"/content/drive/MyDrive/Colab Notebooks\"))\n",
        "\n",
        "# if os.getcwd() != \"/content/drive/MyDrive\":\n",
        "#     os.chdir(\"/content/drive/MyDrive\")\n",
        "\n",
        "# print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgy1Jd8izTUa"
      },
      "outputs": [],
      "source": [
        "# 提前将 requirements.txt 放在 google 云盘上\n",
        "!pip install -r /content/drive/MyDrive/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-1nW3tvzTXo",
        "outputId": "a357be43-f970-4eed-c732-27185991f43e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ch04a\n"
          ]
        }
      ],
      "source": [
        "subdir = \"ch04a\"\n",
        "work_path = \"/content/drive/MyDrive/\" + subdir\n",
        "if not os.path.exists(work_path):\n",
        "    os.mkdir(work_path)\n",
        "os.chdir(work_path)\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98bV6grAzTae",
        "outputId": "aa26f254-ab6a-432f-aa98-b2a014132e54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tree is already the newest version (2.0.2-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n",
            "\u001b[01;34m./\u001b[0m\n",
            "\n",
            "0 directories, 0 files\n"
          ]
        }
      ],
      "source": [
        "!apt-get install tree && tree -a \"./\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Msm2b22G01SS"
      },
      "source": [
        "## Bart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3Srt2iLEZDT",
        "outputId": "a43c8f8c-e9be-49c3-c635-6c5b0abae6ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<transformers.pipelines.text2text_generation.SummarizationPipeline at 0x7d92fc3de190>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "from transformers import pipeline\n",
        "\n",
        "tokenizer = BartTokenizer.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
        "model = BartForConditionalGeneration.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
        "\n",
        "nlp = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
        "nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw4VpvLu0Xkr",
        "outputId": "aedec3df-9534-41b8-e2e5-9e02e947fecd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[01;34m/root/.cache/huggingface\u001b[0m\n",
            "└── \u001b[01;34mhub\u001b[0m\n",
            "    ├── \u001b[01;34m.locks\u001b[0m\n",
            "    │   └── \u001b[01;34mmodels--sshleifer--distilbart-cnn-12-6\u001b[0m\n",
            "    │       ├── \u001b[00m0a39732b2d8be8e493cab3da68b68cc3e28221de.lock\u001b[0m\n",
            "    │       ├── \u001b[00m226b0752cac7789c48f0cb3ec53eda48b7be36cc.lock\u001b[0m\n",
            "    │       ├── \u001b[00m3bac65d18c99463302d12ca75c2220ea714f9c81ce235f205fa818efe71df6ea.lock\u001b[0m\n",
            "    │       ├── \u001b[00mbb2e2ae9c5e339a6e86adac3c946bb853db50d7c588477ddd1622dd2d1fc567c.lock\u001b[0m\n",
            "    │       ├── \u001b[00mbe4d21d94f3b4687e5a54d84bf6ab46ed0f8defd.lock\u001b[0m\n",
            "    │       └── \u001b[00mfade82e22ec4f4b61f6f2eb3986ce4a64a8e23df.lock\u001b[0m\n",
            "    ├── \u001b[01;34mmodels--sshleifer--distilbart-cnn-12-6\u001b[0m\n",
            "    │   ├── \u001b[01;34mblobs\u001b[0m\n",
            "    │   │   ├── \u001b[00m0a39732b2d8be8e493cab3da68b68cc3e28221de\u001b[0m\n",
            "    │   │   ├── \u001b[00m226b0752cac7789c48f0cb3ec53eda48b7be36cc\u001b[0m\n",
            "    │   │   ├── \u001b[00m3bac65d18c99463302d12ca75c2220ea714f9c81ce235f205fa818efe71df6ea\u001b[0m\n",
            "    │   │   ├── \u001b[00mbb2e2ae9c5e339a6e86adac3c946bb853db50d7c588477ddd1622dd2d1fc567c\u001b[0m\n",
            "    │   │   ├── \u001b[00mbe4d21d94f3b4687e5a54d84bf6ab46ed0f8defd\u001b[0m\n",
            "    │   │   └── \u001b[00mfade82e22ec4f4b61f6f2eb3986ce4a64a8e23df\u001b[0m\n",
            "    │   ├── \u001b[01;34m.no_exist\u001b[0m\n",
            "    │   │   └── \u001b[01;34ma4f8f3ea906ed274767e9906dbaede7531d660ff\u001b[0m\n",
            "    │   │       ├── \u001b[00madapter_config.json\u001b[0m\n",
            "    │   │       ├── \u001b[00madded_tokens.json\u001b[0m\n",
            "    │   │       ├── \u001b[00mchat_template.jinja\u001b[0m\n",
            "    │   │       ├── \u001b[00mgeneration_config.json\u001b[0m\n",
            "    │   │       ├── \u001b[00mmodel.safetensors\u001b[0m\n",
            "    │   │       ├── \u001b[00mmodel.safetensors.index.json\u001b[0m\n",
            "    │   │       ├── \u001b[00mspecial_tokens_map.json\u001b[0m\n",
            "    │   │       └── \u001b[00mtokenizer.json\u001b[0m\n",
            "    │   ├── \u001b[01;34mrefs\u001b[0m\n",
            "    │   │   ├── \u001b[00mmain\u001b[0m\n",
            "    │   │   └── \u001b[01;34mrefs\u001b[0m\n",
            "    │   │       └── \u001b[01;34mpr\u001b[0m\n",
            "    │   │           └── \u001b[00m21\u001b[0m\n",
            "    │   └── \u001b[01;34msnapshots\u001b[0m\n",
            "    │       ├── \u001b[01;34ma3e2845d6c2cf0c51bfcab5a7ff1a2f3402b3c33\u001b[0m\n",
            "    │       │   └── \u001b[01;36mmodel.safetensors\u001b[0m -> \u001b[00m../../blobs/bb2e2ae9c5e339a6e86adac3c946bb853db50d7c588477ddd1622dd2d1fc567c\u001b[0m\n",
            "    │       └── \u001b[01;34ma4f8f3ea906ed274767e9906dbaede7531d660ff\u001b[0m\n",
            "    │           ├── \u001b[01;36mconfig.json\u001b[0m -> \u001b[00m../../blobs/fade82e22ec4f4b61f6f2eb3986ce4a64a8e23df\u001b[0m\n",
            "    │           ├── \u001b[01;36mmerges.txt\u001b[0m -> \u001b[00m../../blobs/226b0752cac7789c48f0cb3ec53eda48b7be36cc\u001b[0m\n",
            "    │           ├── \u001b[01;36mpytorch_model.bin\u001b[0m -> \u001b[00m../../blobs/3bac65d18c99463302d12ca75c2220ea714f9c81ce235f205fa818efe71df6ea\u001b[0m\n",
            "    │           ├── \u001b[01;36mtokenizer_config.json\u001b[0m -> \u001b[00m../../blobs/be4d21d94f3b4687e5a54d84bf6ab46ed0f8defd\u001b[0m\n",
            "    │           └── \u001b[01;36mvocab.json\u001b[0m -> \u001b[00m../../blobs/0a39732b2d8be8e493cab3da68b68cc3e28221de\u001b[0m\n",
            "    └── \u001b[00mversion.txt\u001b[0m\n",
            "\n",
            "13 directories, 29 files\n"
          ]
        }
      ],
      "source": [
        "!tree -a ~/.cache/huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD8Q0mp0COac",
        "outputId": "27cc6e57-17b2-48b3-d2c8-14786016c882"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'summary_text': ' The little Stone comes out of these little stones and customers are complaining and bringing them back and we are having to put new jewelry in their holes . You cannot sterilize these in an autoclave because it heats up too much and the glue does not hold up so the second group of these that we used I did not sterilize them that way and the stones still came out .'}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"\"\"\n",
        "We order two different types of jewelry from this\n",
        "company the other jewelry we order is perfect.\n",
        "However with this jewelry I have a few things I\n",
        "don't like. The little Stone comes out of these\n",
        "and customers are complaining and bringing them\n",
        "back and we are having to put new jewelry in their\n",
        "holes. You cannot sterilize these in an autoclave\n",
        "as well because it heats up too much and the glue\n",
        "does not hold up so the second group of these that\n",
        "we used I did not sterilize them that way and the\n",
        "stones still came out. When I use a dermal clamp\n",
        "to put the top on the stones come out immediately.\n",
        "DO not waste your money on this particular product\n",
        "buy the three mm. that has the claws that hold the\n",
        "jewelry in those are perfect. So now I'm stuck\n",
        "with jewelry that I can't sell not good for\n",
        "business.\n",
        "\"\"\"\n",
        "q = nlp(text)\n",
        "q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU-SUAxVIHz1",
        "outputId": "7f364ace-dfac-4e66-8638-4e993ca6a65a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(' The little Stone comes out of these little stones and customers are complaining and bringing '\n",
            " 'them back and we are having to put new jewelry in their holes . You cannot sterilize these in an '\n",
            " 'autoclave because it heats up too much and the glue does not hold up so the second group of '\n",
            " 'these that we used I did not sterilize them that way and the stones still came out .')\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "\n",
        "pp = pprint.PrettyPrinter(indent=0, width=100)\n",
        "pp.pprint(q[0][\"summary_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gjI1wnKxDvpN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
